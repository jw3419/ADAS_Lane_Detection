{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_Time: 134.98919653892517 sec\n",
      "accuracyacy : 96.985714 %\n",
      "Test 이미지 분류 값 : 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "bin_n = 16 # Number of bins\n",
    "\n",
    "def Rotation(img) : \n",
    "    thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    ## 0보다 큰 모든 픽셀 값의 (x,y) 좌표를 구한다.\n",
    "    ## 그리고 이 좌표들을 rotated 연산을 하는데 사용한다.\n",
    "    coords = np.column_stack(np.where(thresh>0))\n",
    "    \n",
    "    ## cv2.minAreaRect : 모양에 외접하면서 면적이 가장 작은 직사각형을 구한다.\n",
    "    ## 그 좌표가 주어진 마지막 요소는 angle로 사용\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    \n",
    "    if angle < -45 :\n",
    "        angle = -(90 + angle)\n",
    "    else :\n",
    "        angle = -angle\n",
    "    \n",
    "    h,w = img.shape[:2]\n",
    "    center = (w//2, h//2)\n",
    "    \n",
    "    ## Affine Transform을 위한 Matrix 구하기\n",
    "    ## 1.0으로 scale 유지\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    \n",
    "    ## 보간법으로 Cubic 사용\n",
    "    ## cv2.BORDER_REPLICATE : 원본의 가장 밖의 테투리에서의 행이나 열은 추가 테두리로 복제된다.\n",
    "    rotated = cv2.warpAffine(img, M, (w,h), flags = cv2.INTER_CUBIC, borderMode = cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    return rotated\n",
    "\n",
    "def HOG(img):\n",
    "    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)   ## x, y방향으로 Gradient를 구한다.\n",
    "    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
    "    mag, ang = cv2.cartToPolar(gx, gy)      ## magnitude와 angle값을 구하는 식이 있으나 라이브러리로 한번에 처리한다.\n",
    "    bins = np.int32(bin_n*ang/(2*np.pi))    ## 360도를 16개 구간으로 나누었으니, ang값이 16개 구간 중 어디에 속하는지 계산한다.\n",
    "    \n",
    "    ## 28x28 orientation map을 4등분 한다. ( 1개 block = 14x14 pixel , 4개의 7x7 cell )\n",
    "    bin_cells = bins[:14,:14], bins[14:,:14], bins[:14,14:], bins[14:,14:]\n",
    "    mag_cells = mag[:14,:14], mag[14:,:14], mag[:14,14:], mag[14:,14:]\n",
    "    \n",
    "    ## 각각의 block의 orientation을 구함\n",
    "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    \n",
    "    ## 각 block의 Orientation을 이어 붙여서 descriptor로 만든다.\n",
    "    hist = np.hstack(hists)     # hist is a 64 bit vector\n",
    "    \n",
    "    return hist\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    # Train 데이터와 Test 데이터 나누기\n",
    "    split_ratio = 0.8\n",
    "    n_train = int(split_ratio * mnist.data.shape[0])\n",
    "    \n",
    "    train_set = mnist.data[:n_train]\n",
    "    test_set = mnist.data[n_train:]\n",
    "    \n",
    "    ## 각각의 training 이미지를 정방향으로 Ratation\n",
    "    rotated = []\n",
    "    for i in range(0, len(train_set)) :\n",
    "        rotated.append( Rotation(np.array(train_set[i].reshape(28,28), np.uint8)) )\n",
    "        \n",
    "    ## Rotation한 이미지로 HOG Descriptor 계산\n",
    "    hogdata = []\n",
    "    for i in range(0, len(rotated)) :\n",
    "        hogdata.append( HOG(np.array(rotated[i].reshape(28,28), np.uint8)) )\n",
    "    \n",
    "    ## HOG를 거쳐서 나온 descriptor와 각각의 Training Data의 Label로 SVM 지도학습 수행\n",
    "    ## SVM을 사용하여 지도학습을 수행할 경우에 Data set을 비선형으로 분류할지, 선형으로 분류할지 정해야한다.\n",
    "    ## 그러기 위해서는 자신의 Data set을 좌표평면에 뿌려 확인하는 방법이 필요할 것 같다.\n",
    "    ## kernel = linear(선형), kernel = rbf (비선형)\n",
    "    trainData = np.float32(hogdata).reshape(-1,64)\n",
    "    trainLabel = mnist.target[:n_train]\n",
    "    \n",
    "    clf = svm.SVC(kernel='rbf')\n",
    "    clf.fit(trainData, trainLabel)\n",
    "    \n",
    "    ## 위에서 수행한 지도학습 모델에 input값으로 Test 이미지의 Hog Descriptor를 넣어서 이미지의 그려진 숫자 예측\n",
    "    rotated = []\n",
    "    for i in range(0, len(test_set)) :\n",
    "        rotated.append( Rotation(np.array(test_set[i].reshape(28,28), np.uint8)) )\n",
    "    \n",
    "    hogdata = []\n",
    "    for i in range(0, len(rotated)) :\n",
    "        hogdata.append( HOG(np.array(rotated[i].reshape(28,28), np.uint8)) )\n",
    "        \n",
    "    testData = np.float32(hogdata).reshape(-1,64)\n",
    "    result = clf.predict(testData)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Total_Time: {} sec\".format(end_time-start_time))\n",
    "    \n",
    "    ## 정확도 검사\n",
    "    testLabel = mnist.target[n_train:]\n",
    "    correct = 0\n",
    "    for i in range(0, len(result)) :\n",
    "        if result[i] == testLabel[i] :\n",
    "            correct += 1\n",
    "    accuracy = 100 * correct/len(result)\n",
    "    print('accuracyacy : %lf %%' %accuracy)\n",
    "    \n",
    "    ## Test 이미지 분류 값 출력\n",
    "    testImage_value = clf.predict(testData[129].reshape(1,-1))\n",
    "    print('Test 이미지 분류 값 : %s' % testImage_value[0])\n",
    "    \n",
    "    cv2.imshow('Test Image', test_set[129].reshape(28,28))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
